{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1. scikit-learn + Naive Bayes\n",
    "\n",
    "<img src=\"http://media.giphy.com/media/2lbhL8dSGMh8I/giphy.gif\"  width=\"200\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le module de Machine Learning en Python : scitkit-learn (sklearn)\n",
    "http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan :\n",
    "\n",
    "   [- Iris dataset](#1)\n",
    "   \n",
    "   [- Naive Bayes](#2)\n",
    "   \n",
    "   [- Mon Naive Bayes](#3)\n",
    "   \n",
    "   [- Tests](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://78.media.tumblr.com/ec97315a70ebd605ac05f3b91feadaa5/tumblr_monmpxBfcM1qirapio1_500.gif\" width = 200>\n",
    "<a id=\"1\"></a> \n",
    " \n",
    "# 1. Iris dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va chercher le dataset **iris** dans le module sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.1,  3.5,  1.4,  0.2],\n",
       "       [ 4.9,  3. ,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.3,  0.2],\n",
       "       [ 4.6,  3.1,  1.5,  0.2],\n",
       "       [ 5. ,  3.6,  1.4,  0.2],\n",
       "       [ 5.4,  3.9,  1.7,  0.4],\n",
       "       [ 4.6,  3.4,  1.4,  0.3],\n",
       "       [ 5. ,  3.4,  1.5,  0.2],\n",
       "       [ 4.4,  2.9,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5.4,  3.7,  1.5,  0.2],\n",
       "       [ 4.8,  3.4,  1.6,  0.2],\n",
       "       [ 4.8,  3. ,  1.4,  0.1],\n",
       "       [ 4.3,  3. ,  1.1,  0.1],\n",
       "       [ 5.8,  4. ,  1.2,  0.2],\n",
       "       [ 5.7,  4.4,  1.5,  0.4],\n",
       "       [ 5.4,  3.9,  1.3,  0.4],\n",
       "       [ 5.1,  3.5,  1.4,  0.3],\n",
       "       [ 5.7,  3.8,  1.7,  0.3],\n",
       "       [ 5.1,  3.8,  1.5,  0.3],\n",
       "       [ 5.4,  3.4,  1.7,  0.2],\n",
       "       [ 5.1,  3.7,  1.5,  0.4],\n",
       "       [ 4.6,  3.6,  1. ,  0.2],\n",
       "       [ 5.1,  3.3,  1.7,  0.5],\n",
       "       [ 4.8,  3.4,  1.9,  0.2],\n",
       "       [ 5. ,  3. ,  1.6,  0.2],\n",
       "       [ 5. ,  3.4,  1.6,  0.4],\n",
       "       [ 5.2,  3.5,  1.5,  0.2],\n",
       "       [ 5.2,  3.4,  1.4,  0.2],\n",
       "       [ 4.7,  3.2,  1.6,  0.2],\n",
       "       [ 4.8,  3.1,  1.6,  0.2],\n",
       "       [ 5.4,  3.4,  1.5,  0.4],\n",
       "       [ 5.2,  4.1,  1.5,  0.1],\n",
       "       [ 5.5,  4.2,  1.4,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 5. ,  3.2,  1.2,  0.2],\n",
       "       [ 5.5,  3.5,  1.3,  0.2],\n",
       "       [ 4.9,  3.1,  1.5,  0.1],\n",
       "       [ 4.4,  3. ,  1.3,  0.2],\n",
       "       [ 5.1,  3.4,  1.5,  0.2],\n",
       "       [ 5. ,  3.5,  1.3,  0.3],\n",
       "       [ 4.5,  2.3,  1.3,  0.3],\n",
       "       [ 4.4,  3.2,  1.3,  0.2],\n",
       "       [ 5. ,  3.5,  1.6,  0.6],\n",
       "       [ 5.1,  3.8,  1.9,  0.4],\n",
       "       [ 4.8,  3. ,  1.4,  0.3],\n",
       "       [ 5.1,  3.8,  1.6,  0.2],\n",
       "       [ 4.6,  3.2,  1.4,  0.2],\n",
       "       [ 5.3,  3.7,  1.5,  0.2],\n",
       "       [ 5. ,  3.3,  1.4,  0.2],\n",
       "       [ 7. ,  3.2,  4.7,  1.4],\n",
       "       [ 6.4,  3.2,  4.5,  1.5],\n",
       "       [ 6.9,  3.1,  4.9,  1.5],\n",
       "       [ 5.5,  2.3,  4. ,  1.3],\n",
       "       [ 6.5,  2.8,  4.6,  1.5],\n",
       "       [ 5.7,  2.8,  4.5,  1.3],\n",
       "       [ 6.3,  3.3,  4.7,  1.6],\n",
       "       [ 4.9,  2.4,  3.3,  1. ],\n",
       "       [ 6.6,  2.9,  4.6,  1.3],\n",
       "       [ 5.2,  2.7,  3.9,  1.4],\n",
       "       [ 5. ,  2. ,  3.5,  1. ],\n",
       "       [ 5.9,  3. ,  4.2,  1.5],\n",
       "       [ 6. ,  2.2,  4. ,  1. ],\n",
       "       [ 6.1,  2.9,  4.7,  1.4],\n",
       "       [ 5.6,  2.9,  3.6,  1.3],\n",
       "       [ 6.7,  3.1,  4.4,  1.4],\n",
       "       [ 5.6,  3. ,  4.5,  1.5],\n",
       "       [ 5.8,  2.7,  4.1,  1. ],\n",
       "       [ 6.2,  2.2,  4.5,  1.5],\n",
       "       [ 5.6,  2.5,  3.9,  1.1],\n",
       "       [ 5.9,  3.2,  4.8,  1.8],\n",
       "       [ 6.1,  2.8,  4. ,  1.3],\n",
       "       [ 6.3,  2.5,  4.9,  1.5],\n",
       "       [ 6.1,  2.8,  4.7,  1.2],\n",
       "       [ 6.4,  2.9,  4.3,  1.3],\n",
       "       [ 6.6,  3. ,  4.4,  1.4],\n",
       "       [ 6.8,  2.8,  4.8,  1.4],\n",
       "       [ 6.7,  3. ,  5. ,  1.7],\n",
       "       [ 6. ,  2.9,  4.5,  1.5],\n",
       "       [ 5.7,  2.6,  3.5,  1. ],\n",
       "       [ 5.5,  2.4,  3.8,  1.1],\n",
       "       [ 5.5,  2.4,  3.7,  1. ],\n",
       "       [ 5.8,  2.7,  3.9,  1.2],\n",
       "       [ 6. ,  2.7,  5.1,  1.6],\n",
       "       [ 5.4,  3. ,  4.5,  1.5],\n",
       "       [ 6. ,  3.4,  4.5,  1.6],\n",
       "       [ 6.7,  3.1,  4.7,  1.5],\n",
       "       [ 6.3,  2.3,  4.4,  1.3],\n",
       "       [ 5.6,  3. ,  4.1,  1.3],\n",
       "       [ 5.5,  2.5,  4. ,  1.3],\n",
       "       [ 5.5,  2.6,  4.4,  1.2],\n",
       "       [ 6.1,  3. ,  4.6,  1.4],\n",
       "       [ 5.8,  2.6,  4. ,  1.2],\n",
       "       [ 5. ,  2.3,  3.3,  1. ],\n",
       "       [ 5.6,  2.7,  4.2,  1.3],\n",
       "       [ 5.7,  3. ,  4.2,  1.2],\n",
       "       [ 5.7,  2.9,  4.2,  1.3],\n",
       "       [ 6.2,  2.9,  4.3,  1.3],\n",
       "       [ 5.1,  2.5,  3. ,  1.1],\n",
       "       [ 5.7,  2.8,  4.1,  1.3],\n",
       "       [ 6.3,  3.3,  6. ,  2.5],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 7.1,  3. ,  5.9,  2.1],\n",
       "       [ 6.3,  2.9,  5.6,  1.8],\n",
       "       [ 6.5,  3. ,  5.8,  2.2],\n",
       "       [ 7.6,  3. ,  6.6,  2.1],\n",
       "       [ 4.9,  2.5,  4.5,  1.7],\n",
       "       [ 7.3,  2.9,  6.3,  1.8],\n",
       "       [ 6.7,  2.5,  5.8,  1.8],\n",
       "       [ 7.2,  3.6,  6.1,  2.5],\n",
       "       [ 6.5,  3.2,  5.1,  2. ],\n",
       "       [ 6.4,  2.7,  5.3,  1.9],\n",
       "       [ 6.8,  3. ,  5.5,  2.1],\n",
       "       [ 5.7,  2.5,  5. ,  2. ],\n",
       "       [ 5.8,  2.8,  5.1,  2.4],\n",
       "       [ 6.4,  3.2,  5.3,  2.3],\n",
       "       [ 6.5,  3. ,  5.5,  1.8],\n",
       "       [ 7.7,  3.8,  6.7,  2.2],\n",
       "       [ 7.7,  2.6,  6.9,  2.3],\n",
       "       [ 6. ,  2.2,  5. ,  1.5],\n",
       "       [ 6.9,  3.2,  5.7,  2.3],\n",
       "       [ 5.6,  2.8,  4.9,  2. ],\n",
       "       [ 7.7,  2.8,  6.7,  2. ],\n",
       "       [ 6.3,  2.7,  4.9,  1.8],\n",
       "       [ 6.7,  3.3,  5.7,  2.1],\n",
       "       [ 7.2,  3.2,  6. ,  1.8],\n",
       "       [ 6.2,  2.8,  4.8,  1.8],\n",
       "       [ 6.1,  3. ,  4.9,  1.8],\n",
       "       [ 6.4,  2.8,  5.6,  2.1],\n",
       "       [ 7.2,  3. ,  5.8,  1.6],\n",
       "       [ 7.4,  2.8,  6.1,  1.9],\n",
       "       [ 7.9,  3.8,  6.4,  2. ],\n",
       "       [ 6.4,  2.8,  5.6,  2.2],\n",
       "       [ 6.3,  2.8,  5.1,  1.5],\n",
       "       [ 6.1,  2.6,  5.6,  1.4],\n",
       "       [ 7.7,  3. ,  6.1,  2.3],\n",
       "       [ 6.3,  3.4,  5.6,  2.4],\n",
       "       [ 6.4,  3.1,  5.5,  1.8],\n",
       "       [ 6. ,  3. ,  4.8,  1.8],\n",
       "       [ 6.9,  3.1,  5.4,  2.1],\n",
       "       [ 6.7,  3.1,  5.6,  2.4],\n",
       "       [ 6.9,  3.1,  5.1,  2.3],\n",
       "       [ 5.8,  2.7,  5.1,  1.9],\n",
       "       [ 6.8,  3.2,  5.9,  2.3],\n",
       "       [ 6.7,  3.3,  5.7,  2.5],\n",
       "       [ 6.7,  3. ,  5.2,  2.3],\n",
       "       [ 6.3,  2.5,  5. ,  1.9],\n",
       "       [ 6.5,  3. ,  5.2,  2. ],\n",
       "       [ 6.2,  3.4,  5.4,  2.3],\n",
       "       [ 5.9,  3. ,  5.1,  1.8]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://media.giphy.com/media/c1zviFHCf4pq0/giphy.gif\" width = 200>\n",
    "<a id=\"2\"></a> \n",
    " \n",
    "# 2. Naive Bayes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class GaussianNB in module sklearn.naive_bayes:\n",
      "\n",
      "class GaussianNB(BaseNB)\n",
      " |  Gaussian Naive Bayes (GaussianNB)\n",
      " |  \n",
      " |  Can perform online updates to model parameters via `partial_fit` method.\n",
      " |  For details on algorithm used to update feature means and variance online,\n",
      " |  see Stanford CS tech report STAN-CS-79-773 by Chan, Golub, and LeVeque:\n",
      " |  \n",
      " |      http://i.stanford.edu/pub/cstr/reports/cs/tr/79/773/CS-TR-79-773.pdf\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <gaussian_naive_bayes>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  priors : array-like, shape (n_classes,)\n",
      " |      Prior probabilities of the classes. If specified the priors are not\n",
      " |      adjusted according to the data.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  class_prior_ : array, shape (n_classes,)\n",
      " |      probability of each class.\n",
      " |  \n",
      " |  class_count_ : array, shape (n_classes,)\n",
      " |      number of training samples observed in each class.\n",
      " |  \n",
      " |  theta_ : array, shape (n_classes, n_features)\n",
      " |      mean of each feature per class\n",
      " |  \n",
      " |  sigma_ : array, shape (n_classes, n_features)\n",
      " |      variance of each feature per class\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
      " |  >>> Y = np.array([1, 1, 1, 2, 2, 2])\n",
      " |  >>> from sklearn.naive_bayes import GaussianNB\n",
      " |  >>> clf = GaussianNB()\n",
      " |  >>> clf.fit(X, Y)\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  >>> clf_pf = GaussianNB()\n",
      " |  >>> clf_pf.partial_fit(X, Y, np.unique(Y))\n",
      " |  GaussianNB(priors=None)\n",
      " |  >>> print(clf_pf.predict([[-0.8, -1]]))\n",
      " |  [1]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      GaussianNB\n",
      " |      BaseNB\n",
      " |      abc.NewBase\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, priors=None)\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None)\n",
      " |      Fit Gaussian Naive Bayes according to X, y\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples\n",
      " |          and n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |             Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      " |      Incremental fit on a batch of samples.\n",
      " |      \n",
      " |      This method is expected to be called several times consecutively\n",
      " |      on different chunks of a dataset so as to implement out-of-core\n",
      " |      or online learning.\n",
      " |      \n",
      " |      This is especially useful when the whole dataset is too big to fit in\n",
      " |      memory at once.\n",
      " |      \n",
      " |      This method has some performance and numerical stability overhead,\n",
      " |      hence it is better to call partial_fit on chunks of data that are\n",
      " |      as large as possible (as long as fitting in the memory budget) to\n",
      " |      hide the overhead.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape (n_samples, n_features)\n",
      " |          Training vectors, where n_samples is the number of samples and\n",
      " |          n_features is the number of features.\n",
      " |      \n",
      " |      y : array-like, shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      classes : array-like, shape (n_classes,), optional (default=None)\n",
      " |          List of all the classes that can possibly appear in the y vector.\n",
      " |      \n",
      " |          Must be provided at the first call to partial_fit, can be omitted\n",
      " |          in subsequent calls.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      " |          Weights applied to individual samples (1. for unweighted).\n",
      " |      \n",
      " |          .. versionadded:: 0.17\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Returns self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseNB:\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Perform classification on an array of test vectors X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape = [n_samples]\n",
      " |          Predicted target values for X\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Return log-probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the log-probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test vector X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = [n_samples, n_features]\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array-like, shape = [n_samples, n_classes]\n",
      " |          Returns the probability of the samples for each class in\n",
      " |          the model. The columns correspond to the classes in sorted\n",
      " |          order, as they appear in the attribute `classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Returns the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape = (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like, shape = (n_samples) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like, shape = [n_samples], optional\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(GaussianNB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module sklearn.naive_bayes:\n",
      "\n",
      "fit(self, X, y, sample_weight=None) method of sklearn.naive_bayes.GaussianNB instance\n",
      "    Fit Gaussian Naive Bayes according to X, y\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    X : array-like, shape (n_samples, n_features)\n",
      "        Training vectors, where n_samples is the number of samples\n",
      "        and n_features is the number of features.\n",
      "    \n",
      "    y : array-like, shape (n_samples,)\n",
      "        Target values.\n",
      "    \n",
      "    sample_weight : array-like, shape (n_samples,), optional (default=None)\n",
      "        Weights applied to individual samples (1. for unweighted).\n",
      "    \n",
      "        .. versionadded:: 0.17\n",
      "           Gaussian Naive Bayes supports fitting with *sample_weight*.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    self : object\n",
      "        Returns self.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "help(gnb.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 150 points : 6\n"
     ]
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\"\n",
    "       % (iris.data.shape[0],(iris.target != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150L, 4L)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 23,  39,  33, 134,  88,  10,  73, 130,  12, 148,  27, 109,  99,\n",
       "        25,  24,  83,  71,  35, 139,  11,  79, 126,  45,  81,  91,  74,\n",
       "        97,  49,  63,  22, 103, 122, 115,  61, 123, 117, 102, 145,  30,\n",
       "        89,  29, 116,  20,  67,   2,  96, 107,   7, 142,  28,  65,  44,\n",
       "        82,  86,  54, 114, 105,  38, 125,  62,  17, 111,  32,  18,  78,\n",
       "       128, 140, 131, 108,  41,  40,   4,  59,  72,  26])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = np.random.choice(range(150), 75, replace=False)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = range(150)\n",
    "test = np.delete(a, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 2 1\n",
      " 1 2 1 1 1 1 1 1 1 1 1 1 2 2 2 1 2 2 2 2 1 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2\n",
      " 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred2 = gnb.fit(iris.data[train,], iris.target[train,]).predict(iris.data[test,])\n",
    "print(y_pred2)\n",
    "print(iris.target[test,])\n",
    "(iris.target[test,] != y_pred2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Etude TRAIN / TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction NB renvoie le pourcentage d'erreur de prédiction du label (les 3 types d'espèce) pour une répétition de nb tirage aléatoire sur un ensemble d'entrainement (train) de taille i (i variant de A à B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NB(A,B,nb):\n",
    "    res = []\n",
    "    for i in range(B-A+1):\n",
    "        temp = 0\n",
    "        for j in range(nb):\n",
    "            train = np.random.choice(range(150), A+i, replace=False)\n",
    "            a = range(150)\n",
    "            test = np.delete(a, train)\n",
    "            y_pred = gnb.fit(iris.data[train,], iris.target[train,]).predict(iris.data[test,])\n",
    "            temp = temp +(iris.target[test,] != y_pred).sum()/(float(len(test)))\n",
    "        res = res + [100*temp/nb]\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xba464e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A = 5\n",
    "B = 145\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(np.linspace(A,B,B-A+1), NB(A,B,100));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"http://media3.giphy.com/media/KYMR9VsDGs3PW/giphy.gif\" width = 200>\n",
    "<a id=\"3\"></a> \n",
    " \n",
    "# 3. Mon Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MonNaiveBayes(train, test):\n",
    "    #TARGET\n",
    "    unique, counts = np.unique(train.target, return_counts=True)\n",
    "    freq = counts/float(len(train.target))\n",
    "    dic = dict(zip(unique, freq)) \n",
    "    estimM = np.zeros(shape=(len(unique),train.data.shape[1]))\n",
    "    estimV = np.zeros(shape=(len(unique),train.data.shape[1])) \n",
    "    #DATA : estimation\n",
    "    l = 0\n",
    "    for tar in unique:\n",
    "        estimM[l,] = np.apply_along_axis(np.mean, 0, train.data[train.target == tar,])\n",
    "        estimV[l,] = np.apply_along_axis(np.var, 0, train.data[train.target == tar,])\n",
    "        l = l+1\n",
    "    \n",
    "    choice = np.zeros(shape=(test.data.shape[0],len(unique)))\n",
    "    #DATA : test \n",
    "    for i in range(test.data.shape[0]):\n",
    "        for j in range(len(unique)):\n",
    "            choice[i,j] = -0.5*sum((test.data[i]-estimM[j])*(test.data[i]-estimM[j])/estimV[j]) + np.log(freq[j]) - 0.5*np.log(np.prod(estimV[j,]))\n",
    "    res = np.argmax(choice, axis=1)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MonNaiveBayes(iris, iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On compare gnb et MonNaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris.data, iris.target).predict(iris.data)\n",
    "y_my_pred = MonNaiveBayes(iris, iris)\n",
    "print(y_pred)\n",
    "print(y_my_pred)\n",
    "(y_pred == y_my_pred).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://media2.giphy.com/media/GgtcDmMa97FhC/200.gif\" width = 200>\n",
    "<a id=\"3\"></a> \n",
    " \n",
    "# 3. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 50\n",
    "\n",
    "iris2 = copy.deepcopy(iris)\n",
    "\n",
    "train = np.random.choice(range(150), nb_train, replace=False)\n",
    "iris2.data = iris2.data[train]\n",
    "iris2.target = iris2.target[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1\n",
      " 1 1 1 2 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 1 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = gnb.fit(iris2.data, iris2.target).predict(iris.data)\n",
    "y_my_pred = MonNaiveBayes(iris2, iris)\n",
    "print(y_pred)\n",
    "print(y_my_pred)\n",
    "(y_pred == y_my_pred).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
